{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "---\n",
    "In this module, we will\n",
    " - analyze resnet nerural network architecture\n",
    " - make predictions over random images with resnet pretrained on ImageNet dataset (***http://www.image-net.org/***)\n",
    " - create your own dataset\n",
    " - finetune resnet for our custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "PyTorch tooling related to image processing can be found in `torchvision` module. Information about accessible pretrained models for PyTorch can be found at ***https://pytorch.org/docs/stable/torchvision/models.html***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18()\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = resnet18.layer4[0].conv1\n",
    "conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.utils import get_image_from_url\n",
    "from image_processing_workshop.visual import plot_image\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default path where to save pretrained models.\n",
    "os.environ[\"TORCH_HOME\"] = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.resnet.model_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "info = resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://media.wired.com/photos/5b86fce8900cb57bbfd1e7ee/master/pass/Jaguar_I-PACE_S_Indus-Silver_065.jpg'\n",
    "img = get_image_from_url(url)\n",
    "plot_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation for resnet, normalization is important!!\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = transformation(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape, transformed_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = transformed_img.unsqueeze(0)\n",
    "resnet18(batch)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's adjust last layer and add softmax, softmax doesn't need training, it's just normalization.\n",
    "resnet18.fc = torch.nn.Sequential(\n",
    "    resnet18.fc, \n",
    "    torch.nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18(batch)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.utils import get_imagenet_category_names\n",
    "from image_processing_workshop.visual import plot_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_imagenet_category_names(use_cache=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classify(transformed_img, resnet18, topn=5, category_names=get_imagenet_category_names(), figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s.w-x.co/util/image/w/411spacex.jpg?v=at&w=815&h=458'\n",
    "img = get_image_from_url(url)\n",
    "transformed_img = transformation(img)\n",
    "plot_classify(transformed_img, resnet18, topn=5, category_names=get_imagenet_category_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with fietuned model on CEOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./models/ceo_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(512, 4),\n",
    "    torch.nn.Softmax(dim=1))\n",
    "model.load_state_dict(state_dict['net'])\n",
    "info = model.eval()\n",
    "\n",
    "# Transformation for resnet, normalization is important!!\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_names = ['Elon Musk', 'Satya Nadella', 'Steve Jobs', 'Sundar Pichai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'http://www.gstatic.com/tv/thumb/persons/476283/476283_v9_ba.jpg'\n",
    "img = get_image_from_url(url)\n",
    "transformed_img = transformation(img)\n",
    "plot_classify(transformed_img, model, topn=5, category_names=ceo_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building of our dataset\n",
    "Let's Google a few (2-4) image categories (different people, few animal species, different cars, flowers etc..) and build dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Scrape image url\n",
    " - go to Google images https://www.google.com/imghp?hl=EN\n",
    " - search image category and scroll a bit through it\n",
    " - run console `Ctrl-Shift-J`\n",
    " - paste javascript snippet to console  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```javascript\n",
    "javascript:document.body.innerHTML = `<a href=\"data:text/csv;charset=utf-8,${escape(Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou).join('\\n'))}\" download=\"urls.txt\">download urls</a>`;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - rename `urls.txt` in `download=\"urls.txt\"` according to category you scrape e.g. `cats.txt`\n",
    " - download image urls\n",
    " - copy `cats.txt` to docker shared folder with this ipython notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download images to proper folder hierarchy\n",
    " - run `scrape_urls` with url file and appropriate category name\n",
    " - each run of `scrape_urls` will create following folder hierarchy\n",
    " \n",
    "`root_folder/train/class_name/*.jpg`   \n",
    "`root_folder/valid/class_name/*.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from image_processing_workshop.utils import scrape_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = './your_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrape_urls('your_urls.txt', category_name='category name', root_folder=root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. First look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "from image_processing_workshop.visual import plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize download images.\n",
    "transformation = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(os.path.join(root_folder, 'valid'), transformation)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grid = utils.make_grid(images)\n",
    "plot_image(image_grid, figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {x: datasets.ImageFolder(os.path.join(root_folder, x), transformation[x]) for x in ['train', 'valid']}\n",
    "loader = {x: torch.utils.data.DataLoader(dataset[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
    "\n",
    "dataset_size = {x: len(dataset[x]) for x in ['train', 'valid']}\n",
    "class_names = dataset['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classify with original renset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classify(dataset['valid'][4][0], resnet18, topn=10, category_names=get_imagenet_category_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune resnet\n",
    "We will use pretrained model on top of which we will place small classification feed forward network. Then we will train this whole architecture in 2 steps:   \n",
    "\n",
    "1) fix of Resnet pretrained weights and tain just our simple added classifier     \n",
    "2) use smaller learning rate and adjust also top layers of Resnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(dataset['train'].classes)\n",
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(512, output_size),\n",
    "    torch.nn.Softmax(dim=1))\n",
    "\n",
    "loss_fce = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic finetuning of last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable all params from training.\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet18.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_acc_and_loss(model, loss_fce, valid_loader):\n",
    "    accuracy = 0\n",
    "    loss = 0\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    for images, labels in valid_loader:\n",
    "        predictions = model(images)\n",
    "        accuracy += (predictions.argmax(dim=1) == labels).type(torch.FloatTensor).mean().item() \n",
    "        loss += loss_fce(predictions, labels).item()\n",
    "    \n",
    "    model.train(mode=was_training)\n",
    "    return accuracy / len(valid_loader) * 100, loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "# Initial params setup.\n",
    "epochs = 20\n",
    "report_period = 3\n",
    "batch_iteration = 0\n",
    "\n",
    "# Storing of some data.\n",
    "train_leak_loss = deque(maxlen=report_period)\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "valid_acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Setup net to train mode and go through one epoch.\n",
    "    model.train()\n",
    "    for images, labels in loader['train']:\n",
    "        batch_iteration += 1\n",
    "        \n",
    "        ##################\n",
    "        # Training Phase #\n",
    "        ##################        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model.forward(images)\n",
    "        loss = loss_fce(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ####################\n",
    "        # Validation Phase #\n",
    "        ####################\n",
    "        train_leak_loss.append(loss.item())\n",
    "        if batch_iteration % report_period == 0:\n",
    "            model.eval()\n",
    "            # We don't want to collect info for gradients from here.\n",
    "            with torch.no_grad():\n",
    "                valid_accuracy, valid_loss = get_valid_acc_and_loss(model, loss_fce, loader['valid'])\n",
    "                \n",
    "            print(f'Epoch: {epoch+1}/{epochs}.. ',\n",
    "                  f\"Train Loss: {round(np.mean(train_leak_loss), 2)}.. \",\n",
    "                  f\"Valid Loss: {round(valid_loss, 2)}.. \",\n",
    "                  f\"Valid Acc: {round(valid_accuracy, 2)}%\")\n",
    "            \n",
    "            train_loss_history.append(np.mean(train_leak_loss))\n",
    "            valid_loss_history.append(valid_loss)\n",
    "            valid_acc_history.append(valid_accuracy)\n",
    "                        \n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra finetuning of resnet layer4\n",
    "Nice reading about advanced strategies for setup of lr here: ***https://www.jeremyjordan.me/nn-learning-rate/***\n",
    "\n",
    " - let's setup as trainable parameters of last layer of resnet model\n",
    " - make learning rate 10 times smaller\n",
    " - re-run previous training cell with adjusted setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['params'] = optimizer.param_groups[0]['params'] + list(model.layer4.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups[0]['lr'] = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go back and re-run training cell**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After all training save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_state = {\n",
    "    'optimizer': optimizer.param_groups,\n",
    "    'net': model.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(training_state, './models/finetuned_resnet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize progress of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Cross Entropy')\n",
    "plt.plot(train_loss_history, label='Train loss')\n",
    "plt.plot(valid_loss_history, label='Valid loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.plot(valid_acc_history, label='Valid acc')\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Acc(%)')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View single images and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.visual import plot_classify, plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classify(dataset['valid'][120][0], model, category_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load reuslts to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.eval import get_results_df\n",
    "from image_processing_workshop.visual import plot_df_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_results_df(model, loader['valid'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Prediction Score')\n",
    "df[df.label_class_name=='one of your categories'].label_class_score.hist(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_df_examples(df.iloc[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Recall and Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.eval import get_rec_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rec_prec(df, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.eval import get_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.eval import get_false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = get_false_positives(df, label_class_name='one of your categories')\n",
    "plot_df_examples(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing_workshop.visual import plot_coocurance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coocurance_matrix(df, use_log=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
