{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "---\n",
    "\n",
    "Pytorch is a framework for building trainable (automatically differentiable) directed acyclic graphs in dynamic manner (in cotrast with e.g. Tensorflow which builds static dags).   \n",
    "\n",
    "Pytorch's main building block are tensors (and it's highlevel abstractions e.g. nn layers) and operation upon those tensors. Using Pytorch we can define minimization problems, which can be solved using torch optimization modules.\n",
    "\n",
    "**Overvoew of torch package**\n",
    " - ***torch.nn***  Highl level abstractions useful for designing neural network architectures including various neural network layer types, loss functions and containers for more complex models.\n",
    " - ***torch.nn.functional***  Similar as torch.nn, not defined in class manner but functional\n",
    " - ***torch.nn.init*** Set of methods used for initialization of torch Tensor.\n",
    " - ***torch.optim*** Module with various optimizers for training of neural networks.\n",
    " - ***torch.utils.data*** Collection of classes for data manipulation.\n",
    " - ***torch.autograd***  Reverse automatic differentiation system which enables automatical computation of the gradients using the chain rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy with Numpy\n",
    "We can use very similar methods as in Numpy to define and operate with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([3, 3], dtype=torch.long, device=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10951122, 0.10335077, 0.23059896],\n",
       "       [0.37116742, 0.39505034, 0.09514046],\n",
       "       [0.56634504, 0.05584924, 0.26862313]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0503, 0.4258, 0.2193],\n",
       "        [0.5295, 0.8487, 0.2291],\n",
       "        [0.3933, 0.9737, 0.6898]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tensor = np.array([[1, 2] ,[3, 4]], dtype=np.float)\n",
    "numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n",
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tensor.shape, torch_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(numpy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic operations with tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n",
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [6., 8.]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor + torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.],\n",
       "        [ 9., 16.]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor * torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7., 10.],\n",
       "        [15., 22.]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.mm(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1162,  0.0655],\n",
       "        [-0.1135,  0.3766]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(torch_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work with shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float)\n",
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1., 2.],\n",
       "        [3., 4., 3., 4.]])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch_tensor, torch_tensor], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(torch_tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 4.]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(torch_tensor, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special tensor properties\n",
    " - ***.requires_grad***  Indication that we want to compute gradinet for this tensor. Pytorch will start to track all operations on it.\n",
    " - ***.grad*** After calling y.backward(), we have in x.grad gradinet defines as dy/dx\n",
    " - ***.grad_fn*** Reference to function that has created the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.],\n",
      "        [ 9., 16.]], grad_fn=<MulBackward0>)\n",
      "tensor(7.5000, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "tt = torch.tensor([[1, 2] ,[3, 4]], dtype=torch.float, requires_grad=True)\n",
    "tt_m = tt * tt\n",
    "print(tt_m)\n",
    "tt_m = tt_m.mean()\n",
    "print(tt_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward1 at 0x7f620a5004a8>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_m.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_m.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute gradinet of all torch.Tensor with .require_grad=True with respect to tt_m variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_m.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 1.0000],\n",
       "        [1.5000, 2.0000]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is way how to stop collecting gradinet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print((tt * tt).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.tensor([[0.20, 0.15],\n",
    "                            [0.30, 0.20],\n",
    "                            [0.86, 0.99],\n",
    "                            [0.91, 0.88]])\n",
    "\n",
    "label_batch = torch.tensor([[1.],\n",
    "                            [1.],\n",
    "                            [-1.],\n",
    "                            [-1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level approach\n",
    "Using just torch.Tensor and torch.autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "training_iterations = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9725],\n",
       "         [ 0.2950]], requires_grad=True),\n",
       " tensor([[-0.0477]], requires_grad=True))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(2, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\"))\n",
    "w2 = torch.randn(1, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\"))\n",
    "w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.06564474105835\n",
      "5000 3.046189308166504\n",
      "10000 1.847407341003418\n",
      "15000 0.681189239025116\n",
      "20000 0.32193928956985474\n"
     ]
    }
   ],
   "source": [
    "for training_iteration in range(training_iterations):\n",
    "    prediction = input_batch.mm(w1)\n",
    "    prediction = torch.tanh(prediction)\n",
    "    prediction = prediction.mm(w2)\n",
    "    prediction = torch.tanh(prediction)\n",
    "    \n",
    "    loss = (prediction - label_batch).pow(2).sum()\n",
    "    if training_iteration % 5000 == 0:\n",
    "        print(training_iteration, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'w1': w1, 'w2': w2}, './ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./ckpt.pth')\n",
    "w1.data = state_dict['w1']\n",
    "w2.data = state_dict['w2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "training_iterations = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(2, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\")))\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(1, 1, dtype=torch.float, requires_grad=True, device=torch.device(\"cpu\")))\n",
    "        \n",
    "    def forward(self, input_batch):\n",
    "        prediction = input_batch.mm(self.w1)\n",
    "        prediction = torch.tanh(prediction)\n",
    "        prediction = prediction.mm(self.w2)\n",
    "        prediction = torch.tanh(prediction)\n",
    "        return prediction\n",
    "\n",
    "simple_nn = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2384],\n",
       "         [-0.6661]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.5653]], requires_grad=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(simple_nn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1391650289297104\n",
      "5000 0.09896896034479141\n",
      "10000 0.07473386824131012\n",
      "15000 0.05894413962960243\n",
      "20000 0.04804077371954918\n"
     ]
    }
   ],
   "source": [
    "for training_iteration in range(training_iterations):\n",
    "    prediction = simple_nn(input_batch)\n",
    "    \n",
    "    loss = (prediction - label_batch).pow(2).sum()\n",
    "    if training_iteration % 5000 == 0:\n",
    "        print(training_iteration, loss.item())\n",
    "\n",
    "    simple_nn.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for p in simple_nn.parameters():\n",
    "            p -= p.grad * learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container approach with torch.nn and  torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import Linear, MSELoss, Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "training_iterations = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer_1 = Linear(2, 1)\n",
    "        self.layer_2 = Linear(1, 1)\n",
    "        \n",
    "    def forward(self, input_batch):\n",
    "        prediction = self.layer_1(input_batch)\n",
    "        prediction = torch.tanh(prediction)\n",
    "        prediction = self.layer_2(prediction)\n",
    "        prediction = torch.tanh(prediction)\n",
    "        return prediction\n",
    "\n",
    "simple_nn = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters\n",
      "\n",
      "[Parameter containing:\n",
      "tensor([[-0.6391, -0.3267]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3719], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.9807]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.9801], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainable parameters\\n\")\n",
    "print(list(simple_nn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fce = MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(simple_nn.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.091989994049072\n",
      "1000 0.011961407959461212\n",
      "2000 0.0050717005506157875\n",
      "3000 0.003165489761158824\n",
      "4000 0.002285524969920516\n",
      "5000 0.0017821136862039566\n",
      "6000 0.001457310514524579\n",
      "7000 0.001230896101333201\n",
      "8000 0.0010642915731295943\n",
      "9000 0.0009367091115564108\n",
      "10000 0.0008359516505151987\n",
      "11000 0.0007544196560047567\n",
      "12000 0.0006871313089504838\n",
      "13000 0.0006306694122031331\n",
      "14000 0.0005826319102197886\n",
      "15000 0.0005412806640379131\n",
      "16000 0.0005053048953413963\n",
      "17000 0.0004737473791465163\n",
      "18000 0.0004458475741557777\n",
      "19000 0.00042099138954654336\n",
      "20000 0.00039872201159596443\n",
      "21000 0.0003786351880989969\n",
      "22000 0.00036047238972969353\n",
      "23000 0.0003439330612309277\n",
      "24000 0.00032881434890441597\n"
     ]
    }
   ],
   "source": [
    "for training_iteration in range(training_iterations):\n",
    "    prediction = simple_nn(input_batch)\n",
    "    \n",
    "    loss = loss_fce(prediction, label_batch)\n",
    "    if training_iteration % 1000 == 0:\n",
    "        print(training_iteration, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9908],\n",
       "        [ 0.9817],\n",
       "        [-0.9867],\n",
       "        [-0.9830]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.load_state_dict(simple_nn.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container approach with torch.nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "custom_relu = CustomReLU().apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_relu(torch.tensor([-1,0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
